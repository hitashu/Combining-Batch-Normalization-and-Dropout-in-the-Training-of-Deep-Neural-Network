{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet164_B_IC-2.ipynb","provenance":[{"file_id":"1DaHiCEbysqWuHnMGpLVinJY3FN_aeXPC","timestamp":1618798454779}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPyA5/jpgcXtVRX55R4gVJM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"76d54d3f1097402381d9d945b1360413":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_edad68e68f594eb19b27722bc2e2eee9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5853faa66975414cbbe2c1e71a099cba","IPY_MODEL_4834fb26929f4822b26368c466fda513"]}},"edad68e68f594eb19b27722bc2e2eee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5853faa66975414cbbe2c1e71a099cba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d670e30e5fd54392a615f916bc0d804e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_562b979fd2ed4b1887581ff7e6a8e4d9"}},"4834fb26929f4822b26368c466fda513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_73692f3f85164cc3b82f901c24ef8236","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:06&lt;00:00, 27512475.00it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2299a83be6046f69c42c77fbc430875"}},"d670e30e5fd54392a615f916bc0d804e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"562b979fd2ed4b1887581ff7e6a8e4d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73692f3f85164cc3b82f901c24ef8236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2299a83be6046f69c42c77fbc430875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"FULdXBkv48Jp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618843252112,"user_tz":300,"elapsed":640,"user":{"displayName":"Harshita Ved","photoUrl":"","userId":"02203123290902493390"}},"outputId":"6abb9bb3-f22c-4393-93c8-aa3f97687305"},"source":["import torch\n","print(torch.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v7tiKdJ85HSg"},"source":["import torchvision\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from torch import nn, optim\n","import matplotlib.pyplot as plt\n","from time import time\n","import numpy as np\n","import pandas as pd\n","from six.moves import urllib\n","import random\n","from skimage.util import random_noise\n","from math import log10\n","import torch.nn.functional as F\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6raDokN95JQc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618843252113,"user_tz":300,"elapsed":632,"user":{"displayName":"Harshita Ved","photoUrl":"","userId":"02203123290902493390"}},"outputId":"f9272c16-0093-466f-80f1-b34b52dbcf36"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"HCcwo4sU5Lop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618843252183,"user_tz":300,"elapsed":698,"user":{"displayName":"Harshita Ved","photoUrl":"","userId":"02203123290902493390"}},"outputId":"ec34bfd7-fc3f-4e7a-a84f-c9c8360f65cc"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Apr 19 14:40:52 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s2bms8mo5Ns1","colab":{"base_uri":"https://localhost:8080/","height":151,"referenced_widgets":["76d54d3f1097402381d9d945b1360413","edad68e68f594eb19b27722bc2e2eee9","5853faa66975414cbbe2c1e71a099cba","4834fb26929f4822b26368c466fda513","d670e30e5fd54392a615f916bc0d804e","562b979fd2ed4b1887581ff7e6a8e4d9","73692f3f85164cc3b82f901c24ef8236","c2299a83be6046f69c42c77fbc430875"]},"executionInfo":{"status":"ok","timestamp":1618843258356,"user_tz":300,"elapsed":6867,"user":{"displayName":"Harshita Ved","photoUrl":"","userId":"02203123290902493390"}},"outputId":"5fe7d248-b89b-4c2a-dbf1-1ad13591a153"},"source":["# Read the train and test sets of CIFAR-10 data\n","default_transform = transforms.Compose([transforms.ToTensor()])\n","cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=default_transform)\n","cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=default_transform)\n","print(\"Training set size:\", len(cifar_trainset))\n","print(\"Test set size:\", len(cifar_testset))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76d54d3f1097402381d9d945b1360413","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Training set size: 50000\n","Test set size: 10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0zEqaLul5PwC"},"source":["# Initialize data loader functions\n","BATCH_SIZE = 64\n","train_dataLoader = DataLoader(cifar_trainset, batch_size=BATCH_SIZE, shuffle=True)\n","test_dataLoader = DataLoader(cifar_testset, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOP-4pCQ5UTe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618843258500,"user_tz":300,"elapsed":7001,"user":{"displayName":"Harshita Ved","photoUrl":"","userId":"02203123290902493390"}},"outputId":"a8602b2b-9b40-407e-a4d5-b8c295015c26"},"source":["# Validate shape of the input images\n","dataiter = iter(train_dataLoader)\n","images, labels = dataiter.next()\n","\n","print(images.shape)\n","print(labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([64, 3, 32, 32])\n","torch.Size([64])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z0ZcsAZ35VUW"},"source":["def conv1x1(in_channels, out_channels, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bgWC3YO5XhK"},"source":["def conv3x3(in_channels, out_channels, stride=1, groups=1, dilation=1):\n","    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n","                     stride=stride, padding=1, groups=groups, bias=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frybWYdkJXcq"},"source":["## Variant 2 (Conv2D --> ReLU --> IC)"]},{"cell_type":"code","metadata":{"id":"gvx0lNerJUtD"},"source":["def IC(inputs, p=0.03):\n","  y = nn.Sequential(\n","      nn.BatchNorm2d(inputs),\n","      nn.Dropout(p))\n","\n","  # y = nn.Dropout(p)(y)\n","\n","  return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LG9FqL935ZoE"},"source":["class Bottleneck_IC2(nn.Module):\n","    expansion = 4  # # output cahnnels / # input channels\n","\n","    def __init__(self, inplanes, outplanes, stride=1):\n","        assert outplanes % self.expansion == 0\n","        super(Bottleneck_IC2, self).__init__()\n","        self.inplanes = inplanes\n","        self.outplanes = outplanes\n","        self.bottleneck_planes = int(outplanes / self.expansion)\n","        self.stride = stride\n","\n","        self._make_layer()\n","\n","    def _make_layer(self):\n","        # conv 1x1\n","        # self.bn1 = nn.BatchNorm2d(self.inplanes)\n","        \n","        self.conv1 = nn.Conv2d(self.inplanes, self.bottleneck_planes,\n","                               kernel_size=1, stride=self.stride, bias=False)\n","        self.IC1 = IC(self.bottleneck_planes)\n","        # conv 3x3\n","        # self.bn2 = nn.BatchNorm2d(self.bottleneck_planes)\n","        \n","        self.conv2 = nn.Conv2d(self.bottleneck_planes, self.bottleneck_planes,\n","                               kernel_size=3, stride=1, padding=1, bias=False)\n","        self.IC2 = IC(self.bottleneck_planes)\n","        # conv 1x1\n","        # self.bn3 = nn.BatchNorm2d(self.bottleneck_planes)\n","        \n","        self.conv3 = nn.Conv2d(self.bottleneck_planes, self.outplanes, kernel_size=1,\n","                               stride=1)\n","        self.IC3 = IC(self.outplanes)\n","\n","        if self.inplanes != self.outplanes:\n","            self.shortcut = nn.Conv2d(self.inplanes, self.outplanes, kernel_size=1,\n","                                      stride=self.stride, bias=False)\n","        else:\n","            self.shortcut = None\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        residual = x\n","  \n","        out = self.conv1(x)\n","        out = self.relu(out)\n","        out = self.IC1(out)\n","\n","        out = self.conv2(out)\n","        out = self.relu(out)\n","        out = self.IC2(out)\n","\n","        out = self.conv3(out)\n","        out = self.relu(out)\n","        out = self.IC3(out)\n","\n","        if self.shortcut is not None:\n","            residual = self.shortcut(residual)\n","\n","        out += residual\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWMw685P5hcL"},"source":["class ResNet(nn.Module):\n","    def __init__(self, block, depth, output_classes=10):\n","        assert (depth - 2) % 9 == 0  # 164 or 1001\n","        super(ResNet, self).__init__()\n","        n = int((depth - 2) / 9)\n","        nstages = [16, 64, 128, 256]\n","        # one conv at the beginning (spatial size: 32x32)\n","        self.conv1 = nn.Conv2d(3, nstages[0], kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","\n","        # use `block` as unit to construct res-net\n","        # Stage 0 (spatial size: 32x32)\n","        self.layer1 = self._make_layer(block, nstages[0], nstages[1], n)\n","        # Stage 1 (spatial size: 32x32)\n","        self.layer2 = self._make_layer(block, nstages[1], nstages[2], n, stride=2)\n","        # Stage 2 (spatial size: 16x16)\n","        self.layer3 = self._make_layer(block, nstages[2], nstages[3], n, stride=2)\n","        # Stage 3 (spatial size: 8x8)\n","        self.bn = nn.BatchNorm2d(nstages[3])\n","        self.relu = nn.ReLU(inplace=True)\n","        # classifier\n","        self.avgpool = nn.AvgPool2d(8)\n","        self.fc = nn.Linear(nstages[3], output_classes)\n","\n","        # weight initialization\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, inplanes, outplanes, nstage, stride=1):\n","        layers = []\n","        layers.append(block(inplanes, outplanes, stride))\n","        for i in range(1, nstage):\n","            layers.append(block(outplanes, outplanes, stride=1))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.relu(self.bn(x))\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAnowr4f5yQ7"},"source":["def get_accuracy(model, dataloader):\n","  \"\"\"\n","    Function to compute accuracy given a model (of class nn) and a dataloader object\n","  \"\"\"\n","  \n","  model.eval()\n","  correct_predictions = 0\n","  with torch.no_grad():\n","    for images, labels in dataloader:\n","      imgs = images.to(device)\n","      lbls = labels.to(device)\n","      # images = images.view(images.shape[0], -1)\n","      output = model(imgs)\n","      _, predicted = torch.max(output.data, 1)\n","      correct_predictions += (predicted == lbls).sum().item()\n","  accuracy = (correct_predictions / len(dataloader.dataset)) * 100\n","  return(accuracy)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTf6XRRc5y5Q"},"source":["def train_network(model, num_epochs, learning_rate, train_dataLoader, test_dataLoader, lr_update_rule):\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","  train_accuracy_list, test_accuracy_list, train_loss_list = [], [], [] \n","  for epoch in range(num_epochs):\n","    running_loss = 0\n","    for images, labels in train_dataLoader:\n","      imgs = images.to(device)\n","      lbls = labels.to(device)\n","  \n","      # Training step\n","      optimizer.zero_grad()\n","      out = model(imgs)\n","      loss = criterion(out, lbls)\n","      \n","      # Backpropagate loss\n","      loss.backward()\n","      \n","      # Optimize weights\n","      optimizer.step()\n","      \n","      running_loss += loss.item()\n","    \n","    train_loss = running_loss/len(train_dataLoader)\n","    train_loss_list.append(train_loss)\n","    train_accuracy = get_accuracy(model, train_dataLoader)\n","    train_accuracy_list.append(train_accuracy)\n","    \n","    test_accuracy = get_accuracy(model, test_dataLoader)\n","    test_accuracy_list.append(test_accuracy)\n","    print(\"Epoch: {} \\t Training loss: {} \\t Training accuracy: {} \\t Test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_accuracy))\n","    \n","  return model, train_accuracy_list, test_accuracy_list, train_loss_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWlRuYIj5005"},"source":["# Hyper-parameters\n","EPOCHS = 100\n","lr = 0.001\n","lr_update = {80:0.0001, 120:0.00001, 160:0.000001}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0rUr6jWR94u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"677215d7-0ffe-4d8c-a71d-d4b004b86d96"},"source":["resnet164B_ic2 = ResNet(Bottleneck_IC2, 164,10).to(device)\n","resnet164B_ic2, train_acc_164B_ic2, test_acc_164B_ic2, train_loss_164B_ic2 = train_network(model=resnet164B_ic2,\n","                                                                       num_epochs=EPOCHS,\n","                                                                       learning_rate=lr,\n","                                                                       train_dataLoader=train_dataLoader,\n","                                                                       test_dataLoader=test_dataLoader,\n","                                                                       lr_update_rule=lr_update)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 0 \t Training loss: 1.4858453697560694 \t Training accuracy: 56.644000000000005 \t Test accuracy: 55.169999999999995\n","Epoch: 1 \t Training loss: 1.1012876663366546 \t Training accuracy: 65.06 \t Test accuracy: 62.74999999999999\n","Epoch: 2 \t Training loss: 0.8649503116869866 \t Training accuracy: 72.602 \t Test accuracy: 69.26\n","Epoch: 3 \t Training loss: 0.709034654871582 \t Training accuracy: 79.412 \t Test accuracy: 74.91\n","Epoch: 4 \t Training loss: 0.5934078780281574 \t Training accuracy: 82.818 \t Test accuracy: 76.14999999999999\n","Epoch: 5 \t Training loss: 0.49563262455374996 \t Training accuracy: 86.644 \t Test accuracy: 78.94\n","Epoch: 6 \t Training loss: 0.4178142988735148 \t Training accuracy: 90.658 \t Test accuracy: 80.7\n","Epoch: 7 \t Training loss: 0.3489385208739039 \t Training accuracy: 90.024 \t Test accuracy: 79.73\n","Epoch: 8 \t Training loss: 0.30481681219109186 \t Training accuracy: 91.422 \t Test accuracy: 79.71000000000001\n","Epoch: 9 \t Training loss: 0.2560640240464445 \t Training accuracy: 92.264 \t Test accuracy: 80.17999999999999\n","Epoch: 10 \t Training loss: 0.2207189590939323 \t Training accuracy: 93.948 \t Test accuracy: 80.58\n","Epoch: 11 \t Training loss: 0.19407679398289268 \t Training accuracy: 93.624 \t Test accuracy: 80.07\n","Epoch: 12 \t Training loss: 0.16503673894307042 \t Training accuracy: 95.43199999999999 \t Test accuracy: 80.78999999999999\n","Epoch: 13 \t Training loss: 0.15443511976076818 \t Training accuracy: 93.41000000000001 \t Test accuracy: 79.5\n","Epoch: 14 \t Training loss: 0.15117129434586105 \t Training accuracy: 97.02199999999999 \t Test accuracy: 82.06\n","Epoch: 15 \t Training loss: 0.12280687148375508 \t Training accuracy: 97.586 \t Test accuracy: 82.76\n","Epoch: 16 \t Training loss: 0.12317790647925776 \t Training accuracy: 97.49 \t Test accuracy: 82.25\n","Epoch: 17 \t Training loss: 0.1055762768172852 \t Training accuracy: 97.358 \t Test accuracy: 82.47\n","Epoch: 18 \t Training loss: 0.11515838078692403 \t Training accuracy: 96.516 \t Test accuracy: 81.88\n","Epoch: 19 \t Training loss: 0.10618805865545178 \t Training accuracy: 97.296 \t Test accuracy: 82.52000000000001\n","Epoch: 20 \t Training loss: 0.09379498689087665 \t Training accuracy: 97.032 \t Test accuracy: 82.27\n","Epoch: 21 \t Training loss: 0.09273954498810251 \t Training accuracy: 95.334 \t Test accuracy: 80.0\n","Epoch: 22 \t Training loss: 0.09443156446789956 \t Training accuracy: 96.124 \t Test accuracy: 81.13\n","Epoch: 23 \t Training loss: 0.0771520717320797 \t Training accuracy: 98.35000000000001 \t Test accuracy: 82.39999999999999\n","Epoch: 24 \t Training loss: 0.085191098766823 \t Training accuracy: 97.356 \t Test accuracy: 82.27\n","Epoch: 25 \t Training loss: 0.08182043604590857 \t Training accuracy: 97.86 \t Test accuracy: 82.52000000000001\n","Epoch: 26 \t Training loss: 0.0752375243768177 \t Training accuracy: 97.586 \t Test accuracy: 82.22\n","Epoch: 27 \t Training loss: 0.08050960906521629 \t Training accuracy: 98.374 \t Test accuracy: 83.06\n","Epoch: 28 \t Training loss: 0.07277916363351729 \t Training accuracy: 97.36 \t Test accuracy: 82.14\n","Epoch: 29 \t Training loss: 0.07298125790508317 \t Training accuracy: 97.366 \t Test accuracy: 81.96\n","Epoch: 30 \t Training loss: 0.06939887592945333 \t Training accuracy: 98.416 \t Test accuracy: 82.89\n","Epoch: 31 \t Training loss: 0.06685859573971661 \t Training accuracy: 98.0 \t Test accuracy: 82.49\n","Epoch: 32 \t Training loss: 0.06598955835811222 \t Training accuracy: 97.85000000000001 \t Test accuracy: 82.76\n","Epoch: 33 \t Training loss: 0.06940379388802483 \t Training accuracy: 98.164 \t Test accuracy: 82.48\n","Epoch: 34 \t Training loss: 0.06552261311445942 \t Training accuracy: 99.17 \t Test accuracy: 83.73\n","Epoch: 35 \t Training loss: 0.06241694245355851 \t Training accuracy: 98.872 \t Test accuracy: 83.44\n","Epoch: 36 \t Training loss: 0.06074996162435192 \t Training accuracy: 97.98400000000001 \t Test accuracy: 82.49\n","Epoch: 37 \t Training loss: 0.05878449900647747 \t Training accuracy: 98.678 \t Test accuracy: 83.57\n","Epoch: 38 \t Training loss: 0.05706303634749585 \t Training accuracy: 98.546 \t Test accuracy: 83.27\n","Epoch: 39 \t Training loss: 0.061791425025688435 \t Training accuracy: 98.758 \t Test accuracy: 83.47\n","Epoch: 40 \t Training loss: 0.05724054651827339 \t Training accuracy: 98.30600000000001 \t Test accuracy: 83.50999999999999\n","Epoch: 41 \t Training loss: 0.05973165667251996 \t Training accuracy: 97.664 \t Test accuracy: 82.74000000000001\n","Epoch: 42 \t Training loss: 0.053140336561713894 \t Training accuracy: 98.366 \t Test accuracy: 83.14\n","Epoch: 43 \t Training loss: 0.05212086349022468 \t Training accuracy: 98.964 \t Test accuracy: 84.16\n","Epoch: 44 \t Training loss: 0.0538440901488947 \t Training accuracy: 97.842 \t Test accuracy: 82.78999999999999\n","Epoch: 45 \t Training loss: 0.0593146600684336 \t Training accuracy: 97.924 \t Test accuracy: 82.19\n","Epoch: 46 \t Training loss: 0.04561125936166471 \t Training accuracy: 98.944 \t Test accuracy: 83.86\n","Epoch: 47 \t Training loss: 0.04955931757892365 \t Training accuracy: 98.936 \t Test accuracy: 84.1\n","Epoch: 48 \t Training loss: 0.054603090585546465 \t Training accuracy: 98.72999999999999 \t Test accuracy: 83.46000000000001\n","Epoch: 49 \t Training loss: 0.0450397975039189 \t Training accuracy: 97.832 \t Test accuracy: 81.99\n","Epoch: 50 \t Training loss: 0.05028324585095795 \t Training accuracy: 98.784 \t Test accuracy: 83.88\n","Epoch: 51 \t Training loss: 0.04393669858120371 \t Training accuracy: 98.81400000000001 \t Test accuracy: 83.88\n","Epoch: 52 \t Training loss: 0.045824854591902456 \t Training accuracy: 98.55199999999999 \t Test accuracy: 83.39999999999999\n","Epoch: 53 \t Training loss: 0.0523023681660496 \t Training accuracy: 98.298 \t Test accuracy: 83.12\n","Epoch: 54 \t Training loss: 0.04671513904569387 \t Training accuracy: 98.348 \t Test accuracy: 82.65\n","Epoch: 55 \t Training loss: 0.04854298567635637 \t Training accuracy: 98.848 \t Test accuracy: 83.46000000000001\n","Epoch: 56 \t Training loss: 0.0419503491797039 \t Training accuracy: 98.626 \t Test accuracy: 83.15\n","Epoch: 57 \t Training loss: 0.04766913736641021 \t Training accuracy: 99.0 \t Test accuracy: 83.49\n","Epoch: 58 \t Training loss: 0.042248721794097846 \t Training accuracy: 98.92999999999999 \t Test accuracy: 84.19\n","Epoch: 59 \t Training loss: 0.042293146512668536 \t Training accuracy: 98.618 \t Test accuracy: 83.21\n","Epoch: 60 \t Training loss: 0.04171218715548275 \t Training accuracy: 98.394 \t Test accuracy: 83.05\n","Epoch: 61 \t Training loss: 0.04257954497725013 \t Training accuracy: 98.8 \t Test accuracy: 83.2\n","Epoch: 62 \t Training loss: 0.04124451993842987 \t Training accuracy: 98.678 \t Test accuracy: 83.19\n","Epoch: 63 \t Training loss: 0.04953131150933491 \t Training accuracy: 98.374 \t Test accuracy: 83.16\n","Epoch: 64 \t Training loss: 0.03732057318701084 \t Training accuracy: 98.568 \t Test accuracy: 83.50999999999999\n","Epoch: 65 \t Training loss: 0.0439453902834667 \t Training accuracy: 99.16199999999999 \t Test accuracy: 84.03\n","Epoch: 66 \t Training loss: 0.03682645352225622 \t Training accuracy: 99.022 \t Test accuracy: 83.82\n","Epoch: 67 \t Training loss: 0.0441083814116249 \t Training accuracy: 97.88799999999999 \t Test accuracy: 82.69999999999999\n","Epoch: 68 \t Training loss: 0.03856086263578171 \t Training accuracy: 98.67 \t Test accuracy: 83.46000000000001\n","Epoch: 69 \t Training loss: 0.042436637972557326 \t Training accuracy: 98.256 \t Test accuracy: 83.19\n","Epoch: 70 \t Training loss: 0.03853316074776132 \t Training accuracy: 99.214 \t Test accuracy: 84.39\n","Epoch: 71 \t Training loss: 0.03689288056857944 \t Training accuracy: 99.05000000000001 \t Test accuracy: 83.67\n","Epoch: 72 \t Training loss: 0.03886303632448533 \t Training accuracy: 97.98599999999999 \t Test accuracy: 82.14\n","Epoch: 73 \t Training loss: 0.03630572197890496 \t Training accuracy: 98.79 \t Test accuracy: 83.0\n","Epoch: 74 \t Training loss: 0.040588690356016185 \t Training accuracy: 99.394 \t Test accuracy: 84.24000000000001\n","Epoch: 75 \t Training loss: 0.03687038681323371 \t Training accuracy: 99.484 \t Test accuracy: 84.36\n","Epoch: 76 \t Training loss: 0.03616259193804953 \t Training accuracy: 98.452 \t Test accuracy: 82.82000000000001\n","Epoch: 77 \t Training loss: 0.03605727951761836 \t Training accuracy: 99.10799999999999 \t Test accuracy: 84.23\n","Epoch: 78 \t Training loss: 0.039474574472706664 \t Training accuracy: 96.556 \t Test accuracy: 81.27\n","Epoch: 79 \t Training loss: 0.030000470849853442 \t Training accuracy: 98.92 \t Test accuracy: 84.11999999999999\n","Epoch: 80 \t Training loss: 0.0434264945838375 \t Training accuracy: 98.56 \t Test accuracy: 83.02000000000001\n","Epoch: 81 \t Training loss: 0.02967193804029554 \t Training accuracy: 98.848 \t Test accuracy: 83.39999999999999\n","Epoch: 82 \t Training loss: 0.03697516794763151 \t Training accuracy: 99.11 \t Test accuracy: 84.02\n","Epoch: 83 \t Training loss: 0.03322026698614957 \t Training accuracy: 98.996 \t Test accuracy: 84.21\n","Epoch: 84 \t Training loss: 0.035709988617989095 \t Training accuracy: 98.956 \t Test accuracy: 83.61\n","Epoch: 85 \t Training loss: 0.0348657375038795 \t Training accuracy: 98.80600000000001 \t Test accuracy: 83.55\n","Epoch: 86 \t Training loss: 0.03891772952760258 \t Training accuracy: 98.988 \t Test accuracy: 84.03\n","Epoch: 87 \t Training loss: 0.028832950307030404 \t Training accuracy: 99.064 \t Test accuracy: 83.96000000000001\n","Epoch: 88 \t Training loss: 0.03757421011324389 \t Training accuracy: 99.738 \t Test accuracy: 84.94\n","Epoch: 89 \t Training loss: 0.028919335559152378 \t Training accuracy: 99.226 \t Test accuracy: 83.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lvp-DXrM5hZd"},"source":["import pandas as pd\n","metric_data_ic2 = pd.DataFrame({'Epoch': range(1,EPOCHS+1), 'Train_Acc': train_acc_164B_ic2, 'Test_Acc': test_acc_164B_ic2, 'Train_Loss': train_loss_164B_ic2})\n","metric_data_ic2.to_csv('ResNet164_B_ic2.csv', index=False)\n","torch.save(resnet164B_ic2, 'ResNet164_B_ic2.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gb89V6D55hDH"},"source":[""],"execution_count":null,"outputs":[]}]}